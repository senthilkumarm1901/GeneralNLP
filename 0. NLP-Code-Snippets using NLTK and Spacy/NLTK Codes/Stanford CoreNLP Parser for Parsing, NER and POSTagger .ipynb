{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['JAVAHOME'] = r'D:\\JavaDevelopment Kit\\JDK Installation\\bin'  # Set this to where the JDK is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import StanfordPOSTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'D:\\NLTK Corpus Download\\Stanford API\\stanford-postagger-full-2018-02-27'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "jar = r'D:\\NLTK Corpus Download\\Stanford API\\stanford-postagger-full-2018-02-27\\stanford-postagger.jar'\n",
    "model = r'D:\\NLTK Corpus Download\\Stanford API\\stanford-postagger-full-2018-02-27\\models\\english-left3words-distsim.tagger'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda Setup\\lib\\site-packages\\nltk\\tag\\stanford.py:149: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordPOSTagger, self).__init__(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "pos_tagger = StanfordPOSTagger(model, jar, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Never', 'RB'), ('reveal', 'VB'), ('your', 'PRP$'), ('details', 'NNS'), ('again', 'RB')]\n"
     ]
    }
   ],
   "source": [
    "text = pos_tagger.tag(word_tokenize('Never reveal your details again'))\n",
    "print (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forza/NN and/CC fallout/NN are/VBP not/RB the/DT very/RB best/JJS games/NNS\n"
     ]
    }
   ],
   "source": [
    "text1=''\n",
    "for each in text:\n",
    "    text1=text1+' '+each[0]+'/'+each[1]\n",
    "    text1=text1.strip()\n",
    "print text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pattern=r\"\"\"\n",
    "VP:\n",
    "    {<VB.*>+<RB>*<VB.*>*<RB>*}\n",
    "AP: \n",
    "    {<JJ.*>+<RB.*>*}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tree=[custom_NPChunker.parse(text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Below Scripts are yet to be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tag import StanfordNERTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['JAVAHOME'] = 'C:\\\\Program Files\\\\Java\\\\jdk-9.0.4\\\\bin'  # Set this to where the JDK is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stanford_classifier = r'C:\\Users\\senthil.kumar\\Documents\\Text Mining\\NLP and Topic Modeling Training\\Standford Parser\\stanford-ner-2017-06-09\\classifiers\\english.all.3class.distsim.crf.ser.gz'\n",
    "stanford_ner_path = r'C:\\Users\\senthil.kumar\\Documents\\Text Mining\\NLP and Topic Modeling Training\\Standford Parser\\stanford-ner-2017-06-09\\stanford-ner.jar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "st = StanfordNERTagger(stanford_classifier, stanford_ner_path, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = 'forza and fallout are not the very best games'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = word_tokenize(text)\n",
    "classified_text = st.tag(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'forza', u'O'), (u'and', u'O'), (u'fallout', u'O'), (u'are', u'O'), (u'not', u'O'), (u'the', u'O'), (u'very', u'O'), (u'best', u'O'), (u'games', u'O')]\n"
     ]
    }
   ],
   "source": [
    "print classified_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.parse.stanford import StanfordDependencyParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\senthil.kumar\\Documents\\Text Mining\\NLP and Topic Modeling Training\\Standford Parser\\stanford-parser-full-2017-06-09'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_jar = path + r'\\stanford-parser-3.8.0-models.jar'\n",
    "path_to_models_jar = path + r'\\stanford-parser-3.8.0-models.jar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency_parser = StanfordDependencyParser(path_to_jar=path_to_jar, path_to_models_jar=path_to_models_jar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object triples at 0x000000000397F3A8>\n",
      "((u'games', u'NNS'), u'nsubj', (u'forza', u'NN'))\n",
      "((u'forza', u'NN'), u'cc', (u'and', u'CC'))\n",
      "((u'forza', u'NN'), u'conj', (u'fallout', u'NN'))\n",
      "((u'games', u'NNS'), u'cop', (u'are', u'VBP'))\n",
      "((u'games', u'NNS'), u'neg', (u'not', u'RB'))\n",
      "((u'games', u'NNS'), u'det', (u'the', u'DT'))\n",
      "((u'games', u'NNS'), u'amod', (u'best', u'JJS'))\n",
      "((u'best', u'JJS'), u'advmod', (u'very', u'RB'))\n"
     ]
    }
   ],
   "source": [
    "result = dependency_parser.raw_parse('forza and fallout are not the very best games')\n",
    "dep = next(result)  # get next item from the iterator result\n",
    "print dep.triples()\n",
    "for t in dep.triples():\n",
    "    print t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\senthil.kumar\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import nltk\n",
    "#nltk.downloader.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Be\n",
      "steals\n"
     ]
    }
   ],
   "source": [
    "for every in word_tree:\n",
    "    for subtree in every.subtrees():\n",
    "        if subtree.label()=='VP':\n",
    "            t = ' '.join(word for word, tag in subtree.leaves())\n",
    "            print t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos': 0.0}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid.polarity_scores(\"be\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rough Comparison with NLTK Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 'DT'),\n",
       " ('is', 'VBZ'),\n",
       " ('did', 'VBD'),\n",
       " ('not', 'RB'),\n",
       " ('work', 'VB'),\n",
       " ('well', 'RB')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "Regexp_tokenizing=RegexpTokenizer(\"\\w+\")\n",
    "sent_tokenize_list=nltk.sent_tokenize('forza and fallout are not the very best games. But they are good')\n",
    "func = lambda s: s[0].lower() + s[1:] if s else ''\n",
    "sent_tokenize_list_proper=[func(sent) for sent in sent_tokenize_list]\n",
    "RegEx_Tokenized_Words=[Regexp_tokenizing.tokenize(sentence) for sentence in sent_tokenize_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['forza', 'and', 'fallout', 'are', 'not', 'the', 'very', 'best', 'games'],\n",
       " ['But', 'they', 'are', 'good']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RegEx_Tokenized_Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('forza', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('fallout', 'NN'),\n",
       "  ('are', 'VBP'),\n",
       "  ('not', 'RB'),\n",
       "  ('the', 'DT'),\n",
       "  ('very', 'RB'),\n",
       "  ('best', 'JJS'),\n",
       "  ('games', 'NNS')],\n",
       " [('But', 'CC'), ('they', 'PRP'), ('are', 'VBP'), ('good', 'JJ')]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pos_Tag_list=[nltk.pos_tag(word) for word in RegEx_Tokenized_Words]\n",
    "Pos_Tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fallout', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('great', 'JJ'),\n",
       " ('game', 'NN')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pos_Tag_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "custom_NPChunker = nltk.RegexpParser(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_tree = [custom_NPChunker.parse(w_list) for w_list in Pos_Tag_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tree('S', [('these', 'DT'), Tree('VP', [('are', 'VBP'), ('very', 'RB')]), ('cheap', 'JJ')])]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
